Этот проект представляет собой реализацию модели сегментации изображений с использованием архитектуры U-Net для обработки аэрофотоснимков. Модель обучается на наборе данных с оригинальными изображениями и соответствующими масками. Код включает в себя загрузку данных, предобработку, аугментацию, обучение модели и визуализацию результатов.

Установка
Перед выполнением кода убедитесь, что у вас установлены необходимые библиотеки. Вы можете установить их с помощью следующей команды:

!pip install tensorflow keras albumentations
Загрузка данных
Код загружает набор данных аэрофотоснимков и распаковывает его:

!wget https://storage.yandexcloud.net/academy.ai/CV/aerial_images.zip
!unzip -qo "aerial_images.zip" -d ./dataset
Структура данных
Данные организованы в следующую структуру:

original_images/ — оригинальные изображения
label_images_semantic/ — маски изображений
Предобработка изображений
Функция display отображает входное изображение, оригинальную маску и предсказанную маску:

def display(display_list):
    plt.figure(figsize=(15, 15))
    title = ['Входное изображение', 'Оригинальная маска', 'Предсказанная маска']
    for i in range(len(display_list)):
        plt.subplot(1, len(display_list), i + 1)
        plt.title(title[i])
        plt.imshow(tf.keras.utils.array_to_img(display_list[0]))  # отображаем картинку
        plt.imshow(tf.keras.utils.array_to_img(display_list[i]), alpha=0.5)  # отображаем маску с прозрачностью 50%
        plt.axis('off')
    plt.show()
Генерация данных
Создается класс datasetGenerator для генерации данных из изображений и масок:

class datasetGenerator(keras.utils.Sequence):
    def __init__(self, batch_size, img_size, input_img_path, target_img_path=None, num_classes=NUM_CLASSES, validation=False):
        self.batch_size = batch_size
        self.img_size = img_size
        self.input_img_path = input_img_path
        self.target_img_path = target_img_path
        self.validation = validation

    def __len__(self):
        return len(self.target_img_path) // self.batch_size

    def __getitem__(self, idx):
        ...
        return x, y
Архитектура модели
Определяется модель U-Net с функциями кодирования и декодирования:

def U_Net(img_size, num_classes):
    inputs = Input(img_size)
    skip1, encoder_1 = encoder(inputs, 64)
    ...
    outputs = Conv2D(num_classes, kernel_size=(1, 1), padding="same", activation="softmax")(decoder_4)
    model = Model(inputs, outputs)
    return model
Обучение модели
Модель компилируется и обучается с использованием генераторов данных:

model.compile(
    optimizer='adam',
    loss="categorical_crossentropy",
    metrics=['accuracy']
)

history = model.fit(train_gen,
                    validation_data=val_gen,
                    epochs=epochs,
                    batch_size=batch_size,
                    callbacks=callbacks)
Визуализация результатов
После обучения модели можно визуализировать предсказанные маски:

for index in range(12):
    img = np.array(load_img(val_input_img_path[index], target_size=(256, 256), color_mode='rgb'))
    mask = np.array(load_img(val_target_img_path[index], target_size=(256, 256), color_mode='grayscale'))
    test = model.predict(np.expand_dims(img, 0) / 255)
    test = np.argmax(test, axis=-1)
    display([img.reshape(1, 256, 256, 3)[0], mask, test[0]])
Заключение
Этот проект демонстрирует, как можно использовать глубокое обучение для сегментации аэрофотоснимков. Он может быть расширен и улучшен с использованием различных архитектур и методов аугментации.
