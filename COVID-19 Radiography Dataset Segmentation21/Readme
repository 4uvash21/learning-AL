COVID-19 Radiography Dataset Segmentation
Этот проект представляет собой реализацию модели сегментации изображений, использующей архитектуру U-Net++ для анализа рентгеновских снимков легких. Модель обучается на наборе данных, содержащем изображения с COVID-19, нормальными легкими и пневмонией. Код включает в себя загрузку данных, предобработку, аугментацию, обучение модели и визуализацию результатов.

Установка
Перед выполнением кода убедитесь, что у вас установлены необходимые библиотеки. Вы можете установить их с помощью следующей команды:

!pip install albumentations opendatasets
Загрузка данных
Код загружает набор данных COVID-19 радиографии с Kaggle и распаковывает его:

import opendatasets as op
op.download("https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database/")
!unzip covid19-radiography-database.zip
Структура данных
Данные организованы в следующие папки:

COVID/images/ — изображения с COVID-19
Normal/images/ — нормальные изображения
Viral Pneumonia/images/ — изображения с вирусной пневмонией
Lung_Opacity/images/ — изображения с легочной недостаточностью
Также имеются соответствующие маски для каждого типа изображения.

Предобработка изображений
Функция open_images загружает и нормализует изображения:

def open_images(paths):
    images = []
    for path in paths:
        image = load_img(path, target_size=(IMAGE_SIZE, IMAGE_SIZE))
        image = np.mean(image, axis=-1) / 255.0
        images.append(image)
    return np.array(images)
Аугментация данных
Используется библиотека Albumentations для аугментации изображений:

def get_augmentation():
    return A.Compose([
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.RandomRotate90(p=0.5),
        A.RandomBrightnessContrast(p=0.2),
        A.Normalize(mean=(0.5,), std=(0.5,)),
    ])
Модель
Модель U-Net++ создается с помощью функции unet_plus_plus:

def unet_plus_plus(input_shape):
    inputs = Input(shape=input_shape)
    # Кодировщик, декодер и мост
    ...
    return Model(inputs=[inputs], outputs=[outputs])
Обучение модели
Модель компилируется и обучается с использованием генераторов данных:

model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=[iou_coef])
model.fit(train_generator, epochs=epochs, steps_per_epoch=steps, validation_data=val_generator, validation_steps=steps, callbacks=[early_stopping])
Визуализация результатов
После обучения модели можно визуализировать предсказанные маски:

def predict(images):
    pred = model.predict(images)
    pred[pred>=0.5] = 1
    pred[pred<0.5] = 0
    return pred
Пример использования
В конце кода приведен пример того, как отображать оригинальные изображения, их маски и предсказанные маски.

Заключение
Этот проект демонстрирует, как можно использовать глубокое обучение для сегментации медицинских изображений. Он может быть расширен и улучшен с использованием различных архитектур и методов аугментации.
