# -*- coding: utf-8 -*-
"""Копия блокнота "34.4. Домашняя работа"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hJWFe-o_dNRTSNccjuGJoK4Bhy2wYRGt

Этот проект представляет собой реализацию модели сегментации изображений, использующей архитектуру U-Net++ для анализа рентгеновских снимков легких. Модель обучается на наборе данных, содержащем изображения с COVID-19, нормальными легкими и пневмонией. Код включает в себя загрузку данных, предобработку, аугментацию, обучение модели и визуализацию результатов.
"""

!pip install albumentations

!pip install opendatasets

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import *
from tensorflow.keras.models import *
from tensorflow.keras.losses import *
from tensorflow.keras.optimizers import *
from tensorflow.keras.metrics import *
import tensorflow.keras.backend as K
from tensorflow.keras.preprocessing.image import load_img

import numpy as np
from sklearn.utils import shuffle
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
import cv2
import albumentations as A
import os

import opendatasets as op
op.download("https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database/")

!unzip covid19-radiography-database.zip

import os
os.listdir()

# Путь к папке
folder_path = 'covid19-radiography-database/COVID-19_Radiography_Dataset/Lung_Opacity/'

# Список файлов в папке
os.listdir(folder_path)

#изображения
covid_image_path = 'covid19-radiography-database/COVID-19_Radiography_Dataset/COVID/images/'
normal_image_path = 'covid19-radiography-database/COVID-19_Radiography_Dataset/Normal/images/'
pneumonia_image_path = 'covid19-radiography-database/COVID-19_Radiography_Dataset/Viral Pneumonia/images/'
lung_opacity_image_path = 'covid19-radiography-database/COVID-19_Radiography_Dataset/Lung_Opacity/images/'

# маски
covid_mask_path = 'covid19-radiography-database/COVID-19_Radiography_Dataset/COVID/masks/'
normal_mask_path = 'covid19-radiography-database/COVID-19_Radiography_Dataset/Normal/masks/'
pneumonia_mask_path = 'covid19-radiography-database/COVID-19_Radiography_Dataset/Viral Pneumonia/masks/'
lung_opacity_mask_path = 'covid19-radiography-database/COVID-19_Radiography_Dataset/Lung_Opacity/masks/'

#  изображения и маски
all_image_paths = [[covid_image_path+file for file in os.listdir(covid_image_path)]
                   +[normal_image_path+file for file in os.listdir(normal_image_path)]
                   +[pneumonia_image_path+file for file in os.listdir(pneumonia_image_path)]
                   +[lung_opacity_image_path+file for file in os.listdir(lung_opacity_image_path)]
                  ][0]
all_mask_paths = [[covid_mask_path+file for file in os.listdir(covid_mask_path)]
                  +[normal_mask_path+file for file in os.listdir(normal_mask_path)]
                  +[pneumonia_mask_path+file for file in os.listdir(pneumonia_mask_path)]
                  +[lung_opacity_mask_path+file for file in os.listdir(lung_opacity_mask_path)]
                 ][0]

# Перетасовать массивы
all_image_paths, all_mask_paths = shuffle(all_image_paths, all_mask_paths)

from tensorflow.keras.preprocessing.image import load_img
IMAGE_SIZE = 256

def open_images(paths):
    images = []
    for path in paths:
        image = load_img(path, target_size=(IMAGE_SIZE, IMAGE_SIZE))
        image = np.mean(image, axis=-1)/255.0
        images.append(image)
    return np.array(images)

fig = plt.figure(figsize=(12, 12))
c = 3
r = 3
for i in range(1, c*r +1):
    fig.add_subplot(r, c, i)
    plt.axis('off')
    plt.imshow(open_images([all_image_paths[i-1]])[0], cmap='gray', interpolation='none')
    plt.imshow(open_images([all_mask_paths[i-1]])[0], cmap='Spectral_r', alpha=0.3)
plt.show()

from tensorflow.keras.preprocessing.image import load_img, img_to_array

train_image_paths = all_image_paths[:17000]
train_mask_paths = all_mask_paths[:17000]
val_image_paths = all_image_paths[17000:]
val_mask_paths = all_mask_paths[17000:]

def datagen(image_paths, mask_paths, batch_size=4, augmentation=None):
    while True:  # Бесконечный цикл для генерации данных
        for start in range(0, len(image_paths), batch_size):
            end = min(start + batch_size, len(image_paths))
            batch_image_paths = image_paths[start:end]
            batch_mask_paths = mask_paths[start:end]

            images = []
            masks = []

            for img_path, mask_path in zip(batch_image_paths, batch_mask_paths):
                # Загружаем изображение в градациях серого
                image = load_img(img_path, target_size=(256, 256), color_mode='grayscale')
                mask = load_img(mask_path, target_size=(256, 256), color_mode='grayscale')

                image = img_to_array(image) / 255.0  # Нормализация изображения
                mask = img_to_array(mask) / 255.0  # Нормализация маски

                # Убедитесь, что у вас есть размерность канала
                image = np.expand_dims(image, axis=-1)  # Добавляем размерность канала
                mask = np.expand_dims(mask, axis=-1)  # Добавляем размерность канала

                # Применение аугментации, если она задана
                if augmentation:
                    augmented = augmentation(image=image, mask=mask)
                    image = augmented['image']
                    mask = augmented['mask']

                images.append(image)
                masks.append(mask)

            yield np.array(images), np.array(masks)

from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate
from tensorflow.keras.models import Model

def unet_plus_plus(input_shape):
    inputs = Input(shape=input_shape)

    # Кодировщик
    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)
    p1 = MaxPooling2D((2, 2))(c1)  # Уменьшаем размер

    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)
    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)
    p2 = MaxPooling2D((2, 2))(c2)  # Уменьшаем размер

    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)
    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)
    p3 = MaxPooling2D((2, 2))(c3)  # Уменьшаем размер

    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)
    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)

    # Мост
    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p3)
    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)

    # Декодер
    u4 = UpSampling2D((2, 2))(c5)
    u4 = Conv2D(512, (3, 3), activation='relu', padding='same')(u4)
    u4 = Conv2D(512, (3, 3), activation='relu', padding='same')(u4)

    u3 = UpSampling2D((2, 2))(u4)
    u3 = Conv2D(256, (3, 3), activation='relu', padding='same')(u3)
    u3 = Conv2D(256, (3, 3), activation='relu', padding='same')(u3)

    u2 = UpSampling2D((2, 2))(u3)
    u2 = Conv2D(128, (3, 3), activation='relu', padding='same')(u2)
    u2 = Conv2D(128, (3, 3), activation='relu', padding='same')(u2)

    u1 = UpSampling2D((2, 2))(u2)
    u1 = Conv2D(64, (3, 3), activation='relu', padding='same')(u1)
    u1 = Conv2D(64, (3, 3), activation='relu', padding='same')(u1)

    # Уменьшение размера выходного слоя
    outputs = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(u1)  # Убедитесь, что выход соответствует целевой маске

    # Изменение размера выходного тензора до (256, 256)
    outputs = Conv2D(1, (3, 3), strides=(2, 2), padding='same')(outputs)  # Уменьшаем размер до (256, 256)

    model = Model(inputs=[inputs], outputs=[outputs])
    return model

# Создание модели
model = unet_plus_plus((IMAGE_SIZE, IMAGE_SIZE, 1))
model.summary()

tf.keras.utils.plot_model(model, show_shapes=True)

def iou_coef(y_true, y_pred, smooth=1):
    # Приведение типов к float32
    y_true = K.cast(y_true, dtype='float32')
    y_pred = K.cast(y_pred, dtype='float32')

    intersection = K.sum(K.abs(y_true * y_pred), axis=[1, 2, 3])
    union = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3]) - intersection

    # Обработка деления на ноль
    union = K.clip(union, K.epsilon(), None)
    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)

    return iou

# Аугментация с использованием Albumentations
def get_augmentation():
    return A.Compose([
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.RandomRotate90(p=0.5),
        A.RandomBrightnessContrast(p=0.2),
        A.Normalize(mean=(0.5,), std=(0.5,)),
    ])

def open_images_with_augmentation(paths, augmentation=None):
    images = []
    for path in paths:
        image = load_img(path, target_size=(IMAGE_SIZE, IMAGE_SIZE))
        image = np.mean(image, axis=-1) / 255.0  # Преобразуем в grayscale и нормализуем
        if augmentation:
            augmented = augmentation(image=image)
            image = augmented['image']
        images.append(image)
    return np.array(images)

model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=[iou_coef])

# Обучение модели
batch_size = 16
steps = len(train_image_paths) // batch_size
epochs = 10
# Получаем аугментацию
augmentation = get_augmentation()
# Устанавливаем коллбэк для остановки
early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)

# Пример использования
train_generator = datagen(train_image_paths, train_mask_paths, batch_size=batch_size, augmentation=augmentation)
val_generator = datagen(val_image_paths, val_mask_paths, batch_size=batch_size, augmentation=augmentation)

# Обучение модели
model.fit(train_generator,
          epochs=epochs,
          steps_per_epoch=steps,
          validation_data=val_generator,
          validation_steps=steps,
          callbacks=[early_stopping])

# Оценка модели
batch_size = 8
steps = int(len(val_image_paths) / batch_size)
model.evaluate(datagen(val_image_paths, val_mask_paths, batch_size=batch_size), steps=steps)

def predict(images):
    pred = model.predict(images)
    pred[pred>=0.5] = 1
    pred[pred<0.5] = 0
    return pred

NO_OF_SAMPLES = 5

c = 2
r = NO_OF_SAMPLES
fig = plt.figure(figsize=(8, r*4))
for i in range(1, c*r +1, 2):

    image = open_images([val_image_paths[i-1]]).reshape(-1,IMAGE_SIZE, IMAGE_SIZE, 1)
    mask = open_images([val_mask_paths[i-1]]).reshape(-1,IMAGE_SIZE, IMAGE_SIZE, 1)
    pred = predict(image)

    fig.add_subplot(r, c, i)
    plt.axis('off')
    plt.title('Действительный')
    plt.imshow(image[0], cmap='gray', interpolation='none')
    plt.imshow(mask[0], cmap='Spectral_r', alpha=0.3)

    fig.add_subplot(r, c, i+1)
    plt.axis('off')
    plt.title('Предсказанный')
    plt.imshow(image[0], cmap='gray', interpolation='none')
    plt.imshow(pred[0], cmap='Spectral_r', alpha=0.3)

plt.show()

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import load_img

# Размер изображения
IMAGE_SIZE = 256

# Функция загрузки изображений
def open_images(paths):
    images = []
    for path in paths:
        image = load_img(path, target_size=(IMAGE_SIZE, IMAGE_SIZE))
        image = np.mean(image, axis=-1) / 255.0  # Преобразуем изображение в grayscale и нормализуем
        images.append(image)
    return np.array(images)

# Предположим, что у вас есть предсказанные маски в виде массива
predicted_masks = model.predict(open_images(all_image_paths))  # Предсказание масок

# Настройка графика
fig = plt.figure(figsize=(15, 15))
c = 3  # Количество столбцов
r = 4  # Количество строк

for i in range(10):  # Отображаем 10 изображений
    fig.add_subplot(r, c, i * c + 1)  # Оригинальное изображение
    plt.axis('off')
    plt.title("Оригинальное изображение")
    plt.imshow(open_images([all_image_paths[i]])[0], cmap='gray', interpolation='none')

    fig.add_subplot(r, c, i * c + 2)  # Оригинальная маска
    plt.axis('off')
    plt.title("Оригинальная маска")
    plt.imshow(open_images([all_mask_paths[i]])[0], cmap='Spectral_r', alpha=0.3)

    fig.add_subplot(r, c, i * c + 3)  # Предсказанная маска
    plt.axis('off')
    plt.title("Предсказанная маска")
    plt.imshow(predicted_masks[i].squeeze(), cmap='Spectral_r', alpha=0.3)  # Убедитесь, что форма маски правильная

plt.tight_layout()
plt.show()