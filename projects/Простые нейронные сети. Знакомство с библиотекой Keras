
import numpy as np
dataset = np.loadtxt('https://storage.yandexcloud.net/academy.ai/A_Z_Handwritten_Data.csv', delimiter=',')

X = dataset[:,1:785]
Y = dataset[:,0]

from sklearn.model_selection import train_test_split
(x_train, x_test, y_train, y_test) = train_test_split(X, Y, test_size=0.2, shuffle=True)


import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

word_dict = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X',24:'Y',25:'Z'}

for i in range(40):
    x = x_train[i]
    x = x.reshape((28, 28))
    plt.axis('off')
    im = plt.subplot(5, 8, i+1)
    plt.title(word_dict.get(y_train[i]))
    im.imshow(x, cmap='gray')



# Проверка размерности данных
print(f"x_train shape: {x_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"x_test shape: {x_test.shape}")
print(f"y_test shape: {y_test.shape}")

import matplotlib.pyplot as plt
%matplotlib inline

digit = x_train[0].reshape(28, 28)
fig, ax = plt.subplots(1,1)
ax.set_title('Образец с индеком 0 из нашего набора данных')
ax.imshow(digit, cmap=plt.cm.binary)
plt.show()

сконструируем модель нейронной сети и передадим ей обучающие данные

from keras import models
from keras import layers
model = models.Sequential()
model.add(layers.Dense(128, activation='relu', input_shape=(784,)))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(26, activation='softmax'))

компиляция модели
* **функцию потерь**, которая определяет, как сеть должна оценивать качество своей работы на обучающих данных и, соответственно, как корректировать ее в правильном направлении;
* **оптимизатор** — механизм, с помощью которого сеть будет обновлять себя, опираясь на наблюдаемые данные и функцию потерь;
* **метрики для мониторинга на этапах обучения и тестирования** — здесь нас
будет интересовать только точность (`accuracy` - доля правильно классифицированных изображений).

model.compile(optimizer='rmsprop',
 loss='categorical_crossentropy',
 metrics=['accuracy'])

categorical_crossentropy — это функция потерь, которая используется в качестве сигнала обратной связи для обучения весовых тензоров и которую этап обучения стремится свести к минимуму. Cнижение потерь достигается за счет применения алгоритма стохастического градиентного спуска на небольших пакетах (мини-батчах). Точные правила, управляющие конкретным применением градиентного спуска, определяются оптимизатором rmsprop, который передается в первом аргументе.

Перед обучением модели нам необходимо выполнить предварительную обработку данных, преобразовав их в форму, которую ожидает получить от нас нейронная сеть, и масштабировать их так, чтобы все значения оказались в интервале  [0,1] .

Исходные данные — обучающие изображения — хранятся в трехмерном массиве  (60000,28,28)  типа  uint8 , значениями в котором являются числа в интервале  [0,255] . Мы преобразуем его в массив  (60000,28∗28)  типа  float32  со значениями в интервале  [0,1] .

x_test.shape

# изменение формы тензора
x_train = x_train.reshape((297960, 784))

# Задаем тип данным и нормируем на максимальное значение в тензоре (приводим к диапазону [0, 1])
x_train = x_train.astype('float32') / 255

# изменение формы тензора
x_test = x_test.reshape((74491, 784))

# Задаем тип данным и нормируем на максимальное значение в тензоре (приводим к диапазону [0, 1])
x_test = x_test.astype('float32') / 255

Метка это число. Как нам подать число на 10 нейронов выходного слоя? Для этого нам нужно закодировать метки категорий или как еще говорят "векторизовать метки".

В данном случае прямое кодирование меток заключается в конструировании вектора с нулевыми элементами и со значением 1 в элементе, индекс которого соответствует индексу метки.

Для кодирования в формате onehot encoding в Keras есть готовая функция:

from keras.utils import to_categorical
y_train_one_hot = to_categorical(y_train, 26)
y_test_one_hot = to_categorical(y_test, 26)

Обучение и оценка модели

history = model.fit(x_train, y_train_one_hot, validation_data=(x_test, y_test_one_hot), epochs=10, batch_size=1024)

В процессе обучения отображаются 4 величины:

loss - потери сети на обучающих данных;
accuracy - точность сети на обучающих данных;
val_loss - потери сети на тестовых данных;
val_accuracy - точность сети на тестовых данных.
В данном случае мы достигли точности более 0,98 (>98%) на обучающих данных.

Теперь проверим, как модель распознает контрольный набор, с помощью метода модели evaluate(), передав ему в качестве позиционных аргументов тестовые изображения и метки:

test_loss, test_acc = model.evaluate(x_test, y_test_one_hot)
print('Точность на тестовом образцу:', test_acc)
print('Потери на тестовом образце:', test_loss)

Предсказание

# Выбор нужной картинки из тестовой выборки
n = 23
x = x_test[n]

# Проверка формы данных
print(x.shape)


import numpy as np

# Массив из одного примера, так как нейронка принимает именно массивы примеров (батчи) для распознавания
x = np.expand_dims(x, axis=0)

# Проверка формы данных
print(x.shape)



# Предсказываем выбранную картинку
prediction = model.predict(x)

# Вывод результата - вектор из 10 чисел
print(f'Вектор результата на 10 выходных нейронах: {prediction}')

# Получение и вывод индекса самого большого элемента (это значение цифры, которую распознала сеть)
pred = np.argmax(prediction)
print(f'Распознана цифра: {pred}')
print(f'Правильное значение: {np.argmax(y_test[n])}')

Визуализация процесса обучения
Построим график потерь на этапах обучения и проверки:

import matplotlib.pyplot as plt
%matplotlib inline

history_dict = history.history
loss_values = history_dict['loss']
val_loss_values = history_dict['val_loss']
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, 'bo', label='Потери на обучающей выборке')
plt.plot(epochs, val_loss_values, 'b', label='Потери на тестовой выборке')
plt.title('График потерь')
plt.xlabel('Эпоха обучения')
plt.ylabel('Потери')
plt.legend()
plt.show()

Построим график точности на этапах обучения и проверки:

import matplotlib.pyplot as plt
%matplotlib inline

history_dict = history.history
acc_values = history_dict['accuracy']
val_acc_values = history_dict['val_accuracy']
epochs = range(1, len(acc_values) + 1)
plt.plot(epochs, acc_values, 'bo', label='Точность на обучающей выборке')
plt.plot(epochs, val_acc_values, 'b', label='Точность на тестовой выборке')
plt.title('График точности')
plt.xlabel('Эпоха обучения')
plt.ylabel('Точность')
plt.legend()
plt.show()

Вывод:
Точность на тестовом образцу: 0.9730974435806274
Потери на тестовом образце: 0.09876911342144012

Анализируя по данным и таблицами, могу сказать успешность обучения модели. С каждой эпохой точность обучающих и тестовых выборок не меняется.
